\begin{abstract}
	This paper extends the work done by Papernot et al. in \yrcite{papernot3} on adversarial attacks on image recognition. We investigated whether a reduction in feature dimensionality using principle component analysis (PCA) can maintain a comparable level of misclassification success while increasing computational efficiency. We attacked black-box image classifiers trained on the MNIST dataset by forcing the oracle to misclassify images that were modified with small perturbations. The method we used was two-fold: the target classifier was imitated with a substitute logistic regression model and then the adversarial samples were generated off of the substitute model \cite{papernot3}. The results show that reasonable misclassification rates of $\sim 70\%$ with reduced computation time can be achieved for a PCA-reduced feature set utilizing the Papernot adversarial crafting algorithm.
\end{abstract}